# -*- coding: utf-8 -*-
"""ambitionbox_complete_scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fCxMYRtB676onBHCicnULPGclRhyzpN1
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Accept-Encoding": "gzip, deflate",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "none",
    "Sec-Fetch-User": "?1",
    "Cache-Control": "max-age=0",
}

col= ['Company Name', 'Tags', 'Type', 'Location', 'Rating', 'Total Reviews', 'Active for (Years)', 'Employee Count', 'About']
completeDetailsList= []
for i in range(1,334):
    pageLink= 'https://www.ambitionbox.com/list-of-companies?campaign=desktop_nav&page={}'.format(i)
    content= requests.get(pageLink, headers= HEADERS)
    textContent= content.text
    soup= BeautifulSoup(textContent, 'lxml') #lxml is html the parser
    soup.prettify()
    
    
    no_of_companies_in_curr_page= len(soup.find_all('h2'))

    for x in range(1, no_of_companies_in_curr_page):
        comp_name= soup.find_all('h2')[x-1].text.strip()
        comp_rating_reviews= soup.find_all('div', class_="rating-wrapper")[x-1].text.strip() # company rating
        comp_rating= comp_rating_reviews[0:10]
        comp_rating= comp_rating.strip()
        comp_review= comp_rating_reviews[10:]
        comp_review= comp_review.strip()
        comp_review= comp_review[1:]
        comp_review= comp_review[:-1]

        comp_info= soup.find_all('div', class_='company-basic-info')
        comp_basic_info= comp_info[x-1].find_all('p', class_='infoEntity sbold-list-header')
        size_of_items= len(comp_basic_info)
        if(size_of_items!=4):
            print(comp_name)
            continue
        comp_type= comp_basic_info[0].text.strip()
        comp_loc= comp_basic_info[1].text.strip()
        how_old= comp_basic_info[2].text.strip()
        emp_count= comp_basic_info[3].text.strip()


        tags= ""

        newSoup= soup.find_all('div', class_= 'company-content')[x-1]
        for i2 in newSoup.find_all('a', class_='ab_chip body-medium'):
            tags+=(i2.text.strip())
            tags+='/'
        tags= tags[:-1]
        
    
        about_wrapper= soup.find_all('div', class_='company-content-wrapper')[x-1]
        about=""
        if(about_wrapper.find('p', class_='description body-small')!=None):
            about= about_wrapper.find('p', class_='description body-small').text.strip()

        my_new_list= [comp_name, tags, comp_type, comp_loc, comp_rating, comp_review, how_old, emp_count, about]
        completeDetailsList.append(my_new_list)
    
myDF= pd.DataFrame(completeDetailsList, columns= col)

myDF

myDF.to_csv('Company_Job_Dataset.csv', index= False)

